<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Détection et Transcription Vocale avec IA</title>
    <!-- Tailwind CSS -->
    <script src="https://cdn.tailwindcss.com"></script>
    <!-- ONNX Runtime et VAD scripts -->
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web@1.14.0/dist/ort.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@ricky0123/vad-web@0.0.22/dist/bundle.min.js"></script>
</head>
<body class="bg-gray-100 p-4">
    <div class="container mx-auto max-w-lg">
        <h1 class="text-2xl font-bold mb-6 text-center">Assistant Vocal Intelligent</h1>
        
        <div class="bg-white p-6 rounded-xl shadow-md">
            <div class="mb-6 text-center">
                <div id="status-indicator" class="w-20 h-20 rounded-full mx-auto flex items-center justify-center bg-gray-300 transition-colors duration-300">
                    <svg xmlns="http://www.w3.org/2000/svg" class="h-10 w-10 text-white" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a3 3 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z" />
                    </svg>
                </div>
                <p id="status-text" class="mt-3 font-medium">En attente de démarrer</p>
            </div>
            
            <div class="flex justify-center space-x-4 mb-6">
                <button id="start-button" class="px-4 py-2 rounded-md bg-blue-500 text-white hover:bg-blue-600 transition-colors focus:outline-none focus:ring-2 focus:ring-blue-300">
                    Démarrer
                </button>
                <button id="stop-button" class="px-4 py-2 rounded-md bg-gray-300 text-gray-500 cursor-not-allowed transition-colors" disabled>
                    Arrêter
                </button>
                <button id="mute-button" class="px-4 py-2 rounded-md bg-yellow-500 text-white hover:bg-yellow-600 transition-colors focus:outline-none focus:ring-2 focus:ring-yellow-300 cursor-not-allowed" disabled>
                    Couper Micro
                </button>
            </div>
            
            <div id="audio-segments" class="mb-4">
                <h3 class="font-medium mb-2">Segments audio: <span id="segments-count">0</span></h3>
                <div id="segments-list" class="max-h-32 overflow-y-auto bg-gray-100 p-2 rounded-md text-sm"></div>
            </div>

            <div class="mt-6">
                <h3 class="font-bold text-lg mb-2">Conversation</h3>
                <div id="conversation-list" class="max-h-80 overflow-y-auto bg-gray-100 p-3 rounded-md"></div>
            </div>

            <div class="mt-6">
                <label for="api-key" class="block text-sm font-medium text-gray-700 mb-1">Clé API Groq:</label>
                <input type="password" id="api-key" class="w-full p-2 border border-gray-300 rounded-md focus:outline-none focus:ring-2 focus:ring-blue-300" placeholder="Entrez votre clé API Groq ici">
                <p class="text-xs text-gray-500 mt-1">La clé sera sauvegardée localement pour faciliter son utilisation.</p>
            </div>
        </div>
    </div>

    <script>
        document.addEventListener('DOMContentLoaded', () => {
            // Éléments DOM
            const startButton = document.getElementById('start-button');
            const stopButton = document.getElementById('stop-button');
            const muteButton = document.getElementById('mute-button');
            const statusIndicator = document.getElementById('status-indicator');
            const statusText = document.getElementById('status-text');
            const segmentsCount = document.getElementById('segments-count');
            const segmentsList = document.getElementById('segments-list');
            const conversationList = document.getElementById('conversation-list');
            const apiKeyInput = document.getElementById('api-key');

            // Variables globales
            let myvad = null;
            let segments = [];
            let isMuted = false;
            let mediaStream = null;
            let processing = false;
            let messageHistory = { current: [] };
            let currentTranscriptionAbortController = null;

            // États UI
            const updateUI = (listening, speaking) => {
                if (listening) {
                    startButton.disabled = true;
                    startButton.classList.add('bg-gray-300', 'text-gray-500', 'cursor-not-allowed');
                    startButton.classList.remove('bg-blue-500', 'text-white', 'hover:bg-blue-600');
                    
                    stopButton.disabled = false;
                    stopButton.classList.add('bg-red-500', 'text-white', 'hover:bg-red-600');
                    stopButton.classList.remove('bg-gray-300', 'text-gray-500', 'cursor-not-allowed');
                    
                    muteButton.disabled = false;
                    muteButton.classList.remove('cursor-not-allowed');
                    
                    statusText.textContent = speaking ? 'Parole détectée' : 'En attente de parole';
                    statusIndicator.classList.remove('bg-gray-300');
                    statusIndicator.classList.add(speaking ? 'bg-green-500' : 'bg-yellow-500');
                } else {
                    startButton.disabled = false;
                    startButton.classList.remove('bg-gray-300', 'text-gray-500', 'cursor-not-allowed');
                    startButton.classList.add('bg-blue-500', 'text-white', 'hover:bg-blue-600');
                    
                    stopButton.disabled = true;
                    stopButton.classList.remove('bg-red-500', 'text-white', 'hover:bg-red-600');
                    stopButton.classList.add('bg-gray-300', 'text-gray-500', 'cursor-not-allowed');
                    
                    muteButton.disabled = true;
                    muteButton.classList.add('cursor-not-allowed');
                    muteButton.classList.remove('bg-green-500');
                    muteButton.classList.add('bg-yellow-500');
                    muteButton.textContent = 'Couper Micro';
                    isMuted = false;
                    
                    statusText.textContent = 'En attente de démarrer';
                    statusIndicator.classList.remove('bg-green-500', 'bg-yellow-500', 'bg-red-500', 'bg-blue-500');
                    statusIndicator.classList.add('bg-gray-300');
                }
            };

            // Fonction pour mettre à jour l'état du micro
            const updateMuteState = (mute) => {
                isMuted = mute;
                
                if (mediaStream) {
                    mediaStream.getAudioTracks().forEach(track => {
                        track.enabled = !isMuted;
                    });
                }
                
                if (isMuted) {
                    muteButton.textContent = 'Activer Micro';
                    muteButton.classList.remove('bg-yellow-500', 'hover:bg-yellow-600');
                    muteButton.classList.add('bg-green-500', 'hover:bg-green-600');
                    statusIndicator.classList.remove('bg-yellow-500', 'bg-green-500');
                    statusIndicator.classList.add('bg-red-500');
                    statusText.textContent = 'Microphone coupé';
                } else {
                    muteButton.textContent = 'Couper Micro';
                    muteButton.classList.remove('bg-green-500', 'hover:bg-green-600');
                    muteButton.classList.add('bg-yellow-500', 'hover:bg-yellow-600');
                    statusIndicator.classList.remove('bg-red-500');
                    statusIndicator.classList.add('bg-yellow-500');
                    statusText.textContent = 'En attente de parole';
                }
            };

            // Fonction pour arrêter complètement
            const stopEverything = () => {
                // Arrêter l'enregistrement VAD
                if (myvad) {
                    myvad.pause();
                }
                
                // Arrêter les flux média
                if (mediaStream) {
                    mediaStream.getTracks().forEach(track => track.stop());
                }
                
                // Annuler toute requête API en cours
                if (currentTranscriptionAbortController) {
                    currentTranscriptionAbortController.abort();
                    currentTranscriptionAbortController = null;
                }
                
                // Réinitialiser les variables d'état
                processing = false;
                
                // Mettre à jour l'UI
                updateUI(false, false);
                
                // Ajouter un message d'information dans la conversation
                const infoMessage = document.createElement('div');
                infoMessage.className = 'p-3 mb-2 bg-blue-100 rounded-md text-center';
                infoMessage.textContent = 'Session arrêtée par l\'utilisateur';
                conversationList.appendChild(infoMessage);
                conversationList.scrollTop = conversationList.scrollHeight;
            };

            // Conversion Float32Array en WAV
            const floatTo16BitPCM = (output, offset, input) => {
                for (let i = 0; i < input.length; i++, offset += 2) {
                    const s = Math.max(-1, Math.min(1, input[i]));
                    output.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
                }
            };

            const writeString = (view, offset, string) => {
                for (let i = 0; i < string.length; i++) {
                    view.setUint8(offset + i, string.charCodeAt(i));
                }
            };

            const encodeWAV = (samples, sampleRate = 16000) => {
                const buffer = new ArrayBuffer(44 + samples.length * 2);
                const view = new DataView(buffer);

                /* RIFF identifier */
                writeString(view, 0, 'RIFF');
                /* RIFF chunk length */
                view.setUint32(4, 36 + samples.length * 2, true);
                /* RIFF type */
                writeString(view, 8, 'WAVE');
                /* format chunk identifier */
                writeString(view, 12, 'fmt ');
                /* format chunk length */
                view.setUint32(16, 16, true);
                /* sample format (raw) */
                view.setUint16(20, 1, true);
                /* channel count */
                view.setUint16(22, 1, true);
                /* sample rate */
                view.setUint32(24, sampleRate, true);
                /* byte rate (sample rate * block align) */
                view.setUint32(28, sampleRate * 2, true);
                /* block align (channel count * bytes per sample) */
                view.setUint16(32, 2, true);
                /* bits per sample */
                view.setUint16(34, 16, true);
                /* data chunk identifier */
                writeString(view, 36, 'data');
                /* data chunk length */
                view.setUint32(40, samples.length * 2, true);

                floatTo16BitPCM(view, 44, samples);

                return buffer;
            };

            // Ajouter segment audio
            const addSegment = (audio) => {
                segments.push(audio);
                segmentsCount.textContent = segments.length;
                
                const segment = document.createElement('div');
                segment.className = 'text-sm text-gray-700';
                segment.textContent = `Segment #${segments.length} - ${Math.round(audio.length / 16000 * 100) / 100}s`;
                segmentsList.appendChild(segment);

                transcribeAudio(audio, segments.length);
            };

            // Transcription et chat
            const transcribeAudio = async (audioData, segmentId) => {
                const apiKey = apiKeyInput.value;
                if (!apiKey) {
                    const message = document.createElement('div');
                    message.className = 'p-3 mb-2 bg-red-100 rounded-md';
                    message.innerHTML = `<span class="font-medium">Erreur:</span> Aucune clé API fournie!`;
                    conversationList.appendChild(message);
                    return;
                }

                // Créer un AbortController pour pouvoir annuler la requête
                currentTranscriptionAbortController = new AbortController();
                const signal = currentTranscriptionAbortController.signal;

                try {
                    // Activer le mode traitement
                    processing = true;
                    
                    // Indiquer l'état de traitement dans l'UI
                    statusText.textContent = 'Traitement en cours...';
                    statusIndicator.classList.remove('bg-yellow-500', 'bg-green-500', 'bg-gray-300');
                    statusIndicator.classList.add('bg-blue-500');
                    
                    // Créer un élément pour l'utilisateur
                    const userMessage = document.createElement('div');
                    userMessage.className = 'p-3 mb-2 bg-blue-50 rounded-md flex items-start';
                    userMessage.id = `message-${segmentId}`;
                    userMessage.innerHTML = `
                        <div class="w-8 h-8 rounded-full bg-blue-500 flex items-center justify-center text-white mr-2 flex-shrink-0">
                            <svg xmlns="http://www.w3.org/2000/svg" class="h-4 w-4" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                                <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M16 7a4 4 0 11-8 0 4 4 0 018 0zM12 14a7 7 0 00-7 7h14a7 7 0 00-7-7z" />
                            </svg>
                        </div>
                        <div class="flex-grow">
                            <div class="text-sm text-blue-700 mb-1">Vous</div>
                            <div><span class="inline-block animate-pulse">Transcription en cours...</span></div>
                        </div>
                    `;
                    conversationList.appendChild(userMessage);
                    
                    // Faire défiler vers le bas
                    conversationList.scrollTop = conversationList.scrollHeight;

                    // Convertir l'audio en WAV
                    const wavBuffer = encodeWAV(audioData);
                    const wavBlob = new Blob([wavBuffer], { type: 'audio/wav' });
                    
                    // Créer un FormData pour l'API
                    const formData = new FormData();
                    formData.append('file', wavBlob, 'audio.wav');
                    formData.append('model', 'whisper-large-v3-turbo');
                    formData.append('temperature', '0');
                    formData.append('response_format', 'json');
                    formData.append('language', 'fr');
                    
                    // Transcription
                    const transcriptionResponse = await fetch(
                        "https://api.groq.com/openai/v1/audio/transcriptions",
                        {
                            method: "POST",
                            headers: {
                                Authorization: `Bearer ${apiKey}`,
                            },
                            body: formData,
                            signal: signal,
                        }
                    );

                    if (!transcriptionResponse.ok) {
                        throw new Error(`Erreur de transcription: ${transcriptionResponse.status} - ${transcriptionResponse.statusText}`);
                    }

                    const transcriptionResult = await transcriptionResponse.json();
                    
                    // Mettre à jour le message de l'utilisateur avec la transcription
                    userMessage.querySelector('div:last-child div:last-child').textContent = transcriptionResult.text;
                    
                    // Ajouter la transcription à l'historique des messages
                    messageHistory.current.push({ 
                        role: "user", 
                        content: transcriptionResult.text 
                    });
                    
                    // Créer l'élément pour l'assistant
                    const assistantMessage = document.createElement('div');
                    assistantMessage.className = 'p-3 mb-2 bg-gray-50 rounded-md flex items-start';
                    assistantMessage.id = `response-${segmentId}`;
                    assistantMessage.innerHTML = `
                        <div class="w-8 h-8 rounded-full bg-purple-500 flex items-center justify-center text-white mr-2 flex-shrink-0">
                            <svg xmlns="http://www.w3.org/2000/svg" class="h-4 w-4" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                                <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9.663 17h4.673M12 3v1m6.364 1.636l-.707.707M21 12h-1M4 12H3m3.343-5.657l-.707-.707m2.828 9.9a5 5 0 117.072 0l-.548.547A3.374 3.374 0 0014 18.469V19a2 2 0 11-4 0v-.531c0-.895-.356-1.754-.988-2.386l-.548-.547z" />
                            </svg>
                        </div>
                        <div class="flex-grow">
                            <div class="text-sm text-purple-700 mb-1">Assistant</div>
                            <div><span class="inline-block animate-pulse">Génération de la réponse...</span></div>
                        </div>
                    `;
                    conversationList.appendChild(assistantMessage);
                    
                    // Faire défiler vers le bas
                    conversationList.scrollTop = conversationList.scrollHeight;
                    
                    // Envoyer à l'API Chat
                    const chatResponse = await fetch(
                        "https://api.groq.com/openai/v1/chat/completions",
                        {
                            method: "POST",
                            headers: {
                                Authorization: `Bearer ${apiKey}`,
                                "Content-Type": "application/json",
                            },
                            body: JSON.stringify({
                                messages: messageHistory.current,
                                model: "gemma2-9b-it",
                            }),
                            signal: signal,
                        }
                    );

                    if (!chatResponse.ok) {
                        throw new Error(`Erreur de chat: ${chatResponse.status} - ${chatResponse.statusText}`);
                    }

                    const chatResult = await chatResponse.json();
                    
                    // Ajouter la réponse à l'historique
                    if (chatResult.choices && chatResult.choices[0] && chatResult.choices[0].message) {
                        messageHistory.current.push(chatResult.choices[0].message);
                    }
                    
                    // Mettre à jour le message de l'assistant avec la réponse
                    assistantMessage.querySelector('div:last-child div:last-child').textContent = chatResult.choices[0].message.content;
                    assistantMessage.querySelector('div:last-child div:last-child').classList.remove('animate-pulse');
                    
                    // Réinitialiser l'AbortController une fois terminé
                    currentTranscriptionAbortController = null;
                    
                    // Désactiver le mode traitement
                    processing = false;
                    
                    // Remettre l'UI dans l'état d'écoute
                    statusText.textContent = 'En attente de parole';
                    statusIndicator.classList.remove('bg-blue-500');
                    statusIndicator.classList.add('bg-yellow-500');
                    
                    // Faire défiler vers le bas
                    conversationList.scrollTop = conversationList.scrollHeight;
                } catch (error) {
                    // Vérifier si l'erreur est due à une annulation volontaire
                    if (error.name === 'AbortError') {
                        console.log("Requête annulée volontairement");
                        return;
                    }
                    
                    console.error("Erreur:", error);
                    
                    // Ajouter un message d'erreur
                    const errorMessage = document.createElement('div');
                    errorMessage.className = 'p-3 mb-2 bg-red-100 rounded-md';
                    errorMessage.innerHTML = `<span class="font-medium">Erreur:</span> ${error.message}`;
                    conversationList.appendChild(errorMessage);
                    
                    // Réinitialiser l'AbortController même en cas d'erreur
                    currentTranscriptionAbortController = null;
                    
                    // Désactiver le mode traitement
                    processing = false;
                    
                    // Remettre l'UI dans l'état d'écoute si on n'a pas arrêté complètement
                    if (myvad && myvad.listening) {
                        statusText.textContent = 'En attente de parole';
                        statusIndicator.classList.remove('bg-blue-500');
                        statusIndicator.classList.add('bg-yellow-500');
                    }
                    
                    // Faire défiler vers le bas
                    conversationList.scrollTop = conversationList.scrollHeight;
                }
            };

            // Initialisation et démarrage
            startButton.addEventListener('click', async () => {
                try {
                    myvad = await vad.MicVAD.new({
                        onSpeechStart: () => {
                            console.log("Parole détectée");
                            if (!isMuted && !processing) {
                                updateUI(true, true);
                            }
                        },
                        onSpeechEnd: (audio) => {
                            console.log("Fin de parole");
                            if (!isMuted && !processing) {
                                updateUI(true, false);
                                addSegment(audio);
                            }
                        },
                        onVADMisfire: () => {
                            console.log("Fausse détection");
                        }
                    });
                    
                    mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
                    myvad.start();
                    updateUI(true, false);
                } catch (error) {
                    console.error("Erreur lors de l'initialisation du VAD:", error);
                    statusText.textContent = "Erreur d'initialisation!";
                    
                    const errorMessage = document.createElement('div');
                    errorMessage.className = 'p-3 mb-2 bg-red-100 rounded-md';
                    errorMessage.innerHTML = `<span class="font-medium">Erreur d'initialisation:</span> ${error.message}`;
                    conversationList.appendChild(errorMessage);
                }
            });

            // Arrêter tout - à la fois l'enregistrement et le traitement en cours
            stopButton.addEventListener('click', stopEverything);

            // Couper/activer le micro manuellement
            muteButton.addEventListener('click', () => {
                updateMuteState(!isMuted);
            });

            // Charger la clé API depuis localStorage si disponible
            const savedKey = localStorage.getItem('groq-api-key');
            if (savedKey) {
                apiKeyInput.value = savedKey;
            }

            // Sauvegarder la clé API dans localStorage quand elle change
            apiKeyInput.addEventListener('change', () => {
                localStorage.setItem('groq-api-key', apiKeyInput.value);
            });
        });
    </script>
</body>
</html>