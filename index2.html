<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Détection et Transcription Vocale</title>
    <!-- Tailwind CDN pour le style -->
    <script src="https://cdn.tailwindcss.com"></script>
    <!-- ONNX Runtime et VAD scripts -->
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web@1.14.0/dist/ort.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@ricky0123/vad-web@0.0.22/dist/bundle.min.js"></script>
</head>
<body class="bg-gray-100 p-4">
    <div class="container mx-auto max-w-md">
        <h1 class="text-2xl font-bold mb-6 text-center">Détection et Transcription Vocale</h1>
        
        <div class="bg-white p-6 rounded-lg shadow-md">
            <div class="mb-4">
                <div id="status-indicator" class="w-16 h-16 rounded-full mx-auto flex items-center justify-center bg-gray-300">
                    <svg xmlns="http://www.w3.org/2000/svg" class="h-8 w-8 text-white" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a3 3 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z" />
                    </svg>
                </div>
                <p id="status-text" class="text-center mt-2">En attente de démarrer</p>
            </div>
            
            <div class="flex justify-center space-x-4 mb-4">
                <button id="start-button" class="px-4 py-2 rounded-md bg-blue-500 text-white hover:bg-blue-600">
                    Démarrer
                </button>
                <button id="stop-button" class="px-4 py-2 rounded-md bg-gray-300" disabled>
                    Arrêter
                </button>
                <button id="mute-button" class="px-4 py-2 rounded-md bg-yellow-500 text-white hover:bg-yellow-600" disabled>
                    Couper Micro
                </button>
            </div>
            
            <div>
                <h3 class="font-medium mb-2">Segments audio: <span id="segments-count">0</span></h3>
                <div id="segments-list" class="max-h-32 overflow-y-auto bg-gray-100 p-2 rounded"></div>
            </div>

            <div class="mt-4">
                <h3 class="font-medium mb-2">Transcriptions:</h3>
                <div id="transcription-list" class="max-h-60 overflow-y-auto bg-gray-100 p-2 rounded"></div>
            </div>

            <div class="mt-4">
                <label for="api-key" class="block text-sm font-medium text-gray-700 mb-1">Clé API Groq:</label>
                <input type="password" id="api-key" class="w-full p-2 border border-gray-300 rounded" placeholder="Entrez votre clé API Groq ici">
            </div>
        </div>
    </div>

    <script>
        document.addEventListener('DOMContentLoaded', () => {
            const startButton = document.getElementById('start-button');
            const stopButton = document.getElementById('stop-button');
            const muteButton = document.getElementById('mute-button');
            const statusIndicator = document.getElementById('status-indicator');
            const statusText = document.getElementById('status-text');
            const segmentsCount = document.getElementById('segments-count');
            const segmentsList = document.getElementById('segments-list');
            const transcriptionList = document.getElementById('transcription-list');
            const apiKeyInput = document.getElementById('api-key');

            let myvad = null;
            let segments = [];
            let transcriptions = [];
            let isMuted = false;
            let mediaStream = null;

            const updateUI = (listening, speaking) => {
                if (listening) {
                    startButton.disabled = true;
                    startButton.classList.add('bg-gray-300');
                    startButton.classList.remove('bg-blue-500', 'hover:bg-blue-600');
                    
                    stopButton.disabled = false;
                    stopButton.classList.add('bg-red-500', 'text-white', 'hover:bg-red-600');
                    stopButton.classList.remove('bg-gray-300');
                    
                    muteButton.disabled = false;
                    
                    statusText.textContent = speaking ? 'Parole en cours...' : 'En attente de parole';
                    statusIndicator.classList.remove('bg-gray-300');
                    statusIndicator.classList.add(speaking ? 'bg-green-500' : 'bg-yellow-500');
                } else {
                    startButton.disabled = false;
                    startButton.classList.remove('bg-gray-300');
                    startButton.classList.add('bg-blue-500', 'text-white', 'hover:bg-blue-600');
                    
                    stopButton.disabled = true;
                    stopButton.classList.remove('bg-red-500', 'text-white', 'hover:bg-red-600');
                    stopButton.classList.add('bg-gray-300');
                    
                    muteButton.disabled = true;
                    muteButton.classList.remove('bg-green-500');
                    muteButton.classList.add('bg-yellow-500');
                    muteButton.textContent = 'Couper Micro';
                    isMuted = false;
                    
                    statusText.textContent = 'En attente de démarrer';
                    statusIndicator.classList.remove('bg-green-500', 'bg-yellow-500', 'bg-red-500');
                    statusIndicator.classList.add('bg-gray-300');
                }
            };

            // Fonction pour convertir Float32Array en WAV
            const floatTo16BitPCM = (output, offset, input) => {
                for (let i = 0; i < input.length; i++, offset += 2) {
                    const s = Math.max(-1, Math.min(1, input[i]));
                    output.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
                }
            };

            const writeString = (view, offset, string) => {
                for (let i = 0; i < string.length; i++) {
                    view.setUint8(offset + i, string.charCodeAt(i));
                }
            };

            const encodeWAV = (samples, sampleRate = 16000) => {
                const buffer = new ArrayBuffer(44 + samples.length * 2);
                const view = new DataView(buffer);

                /* RIFF identifier */
                writeString(view, 0, 'RIFF');
                /* RIFF chunk length */
                view.setUint32(4, 36 + samples.length * 2, true);
                /* RIFF type */
                writeString(view, 8, 'WAVE');
                /* format chunk identifier */
                writeString(view, 12, 'fmt ');
                /* format chunk length */
                view.setUint32(16, 16, true);
                /* sample format (raw) */
                view.setUint16(20, 1, true);
                /* channel count */
                view.setUint16(22, 1, true);
                /* sample rate */
                view.setUint32(24, sampleRate, true);
                /* byte rate (sample rate * block align) */
                view.setUint32(28, sampleRate * 2, true);
                /* block align (channel count * bytes per sample) */
                view.setUint16(32, 2, true);
                /* bits per sample */
                view.setUint16(34, 16, true);
                /* data chunk identifier */
                writeString(view, 36, 'data');
                /* data chunk length */
                view.setUint32(40, samples.length * 2, true);

                floatTo16BitPCM(view, 44, samples);

                return buffer;
            };

            const addSegment = (audio) => {
                segments.push(audio);
                segmentsCount.textContent = segments.length;
                
                const segment = document.createElement('div');
                segment.className = 'text-sm text-gray-700';
                segment.textContent = `Segment #${segments.length} - ${Math.round(audio.length / 16000 * 100) / 100}s`;
                segmentsList.appendChild(segment);

                transcribeAudio(audio, segments.length);
            };

            const transcribeAudio = async (audioData, segmentId) => {
    const apiKey = apiKeyInput.value;
    if (!apiKey) {
        const transcription = document.createElement('div');
        transcription.className = 'p-2 mb-2 bg-red-100 rounded';
        transcription.innerHTML = `<b>Segment #${segmentId}:</b> <span class="text-red-600">Aucune clé API fournie!</span>`;
        transcriptionList.appendChild(transcription);
        return;
    }

    try {
        // Créer un élément de chargement
        const loadingItem = document.createElement('div');
        loadingItem.className = 'p-2 mb-2 bg-blue-50 rounded flex items-center';
        loadingItem.id = `loading-${segmentId}`;
        loadingItem.innerHTML = `<b>Segment #${segmentId}:</b> <span class="ml-2">Transcription en cours...</span>`;
        transcriptionList.appendChild(loadingItem);

        // Convertir l'audio en WAV
        const wavBuffer = encodeWAV(audioData);
        const wavBlob = new Blob([wavBuffer], { type: 'audio/wav' });
        
        // Créer un FormData pour l'API
        const formData = new FormData();
        formData.append('file', wavBlob, 'audio.wav');
        formData.append('model', 'whisper-large-v3-turbo');
        formData.append('temperature', '0');
        formData.append('response_format', 'json');
        formData.append('language', 'fr');

        console.log("Envoi de la requête à l'API avec la clé:", apiKey.substring(0, 5) + "...");
        
        // Envoyer la requête à l'API Groq
        const response = await fetch(
            "https://api.groq.com/openai/v1/audio/transcriptions",
            {
                method: "POST",
                headers: {
                    Authorization: `Bearer ${apiKey}`,
                },
                body: formData,
            }
        );

        if (!response.ok) {
            throw new Error(`Erreur HTTP: ${response.status} - ${response.statusText}`);
        }

        const result = await response.json();
        console.log("Réponse de l'API:", result);
        transcriptions.push(result);

        // Remplacer l'élément de chargement par le résultat
        const transcription = document.createElement('div');
        transcription.className = 'p-2 mb-2 bg-green-50 rounded';
        transcription.innerHTML = `<b>Segment #${segmentId}:</b> ${result.text}`;
        transcriptionList.replaceChild(transcription, loadingItem);
    } catch (error) {
        console.error("Erreur de transcription:", error);
        
        // Remplacer l'élément de chargement par un message d'erreur
        const errorItem = document.createElement('div');
        errorItem.className = 'p-2 mb-2 bg-red-100 rounded';
        errorItem.innerHTML = `<b>Segment #${segmentId}:</b> <span class="text-red-600">Erreur: ${error.message}</span>`;
        
        const loadingItem = document.getElementById(`loading-${segmentId}`);
        if (loadingItem) {
            transcriptionList.replaceChild(errorItem, loadingItem);
        } else {
            transcriptionList.appendChild(errorItem);
        }
    }
};
            startButton.addEventListener('click', async () => {
                try {
                    myvad = await vad.MicVAD.new({
                        onSpeechStart: () => {
                            console.log("Parole détectée");
                            if (!isMuted) {
                                updateUI(true, true);
                            }
                        },
                        onSpeechEnd: (audio) => {
                            console.log("Fin de parole");
                            if (!isMuted) {
                                updateUI(true, false);
                                addSegment(audio);
                            }
                        },
                        onVADMisfire: () => {
                            console.log("Fausse détection");
                        }
                    });
                    
                    mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
                    myvad.start();
                    updateUI(true, false);
                } catch (error) {
                    console.error("Erreur lors de l'initialisation du VAD:", error);
                    statusText.textContent = "Erreur d'initialisation!";
                }
            });

            stopButton.addEventListener('click', () => {
                if (myvad) {
                    myvad.pause();
                    if (mediaStream) {
                        mediaStream.getTracks().forEach(track => track.stop());
                    }
                    updateUI(false, false);
                }
            });

            muteButton.addEventListener('click', () => {
                isMuted = !isMuted;
                
                if (mediaStream) {
                    mediaStream.getAudioTracks().forEach(track => {
                        track.enabled = !isMuted;
                    });
                }
                
                if (isMuted) {
                    muteButton.textContent = 'Activer Micro';
                    muteButton.classList.remove('bg-yellow-500');
                    muteButton.classList.add('bg-green-500');
                    statusIndicator.classList.remove('bg-yellow-500', 'bg-green-500');
                    statusIndicator.classList.add('bg-red-500');
                    statusText.textContent = 'Microphone coupé';
                } else {
                    muteButton.textContent = 'Couper Micro';
                    muteButton.classList.remove('bg-green-500');
                    muteButton.classList.add('bg-yellow-500');
                    statusIndicator.classList.remove('bg-red-500');
                    statusIndicator.classList.add('bg-yellow-500');
                    statusText.textContent = 'En attente de parole';
                }
            });

            // Charger la clé API depuis localStorage si disponible
            const savedKey = localStorage.getItem('groq-api-key');
            if (savedKey) {
                apiKeyInput.value = savedKey;
            }

            // Sauvegarder la clé API dans localStorage quand elle change
            apiKeyInput.addEventListener('change', () => {
                localStorage.setItem('groq-api-key', apiKeyInput.value);
            });
        });
    </script>
</body>
</html>